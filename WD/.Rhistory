sample.lowerlimit <- confint(onestudy.result)["x","2.5 %"]
sample.upperlimit <- confint(onestudy.result)["x","97.5 %"]
lines(x=c(sample.lowerlimit,sample.upperlimit),y=c(i,i),col=i)
cat("lower=",  round(sample.lowerlimit,2),
", true=", round(TrueSlope,2),
", upper=",round(sample.upperlimit,2),sep="")
if ((sample.lowerlimit < TrueSlope) && (TrueSlope < sample.upperlimit)) {
cat(", CI contains true? yes\n")
CI.contains.true.slope <- append(CI.contains.true.slope,1)
} else {
cat(", CI contains true? no\n")
CI.contains.true.slope <- append(CI.contains.true.slope,0)
}
}
# How many times did the CI of the slope contain the true slope?
hist(CI.contains.true.slope)
mean(CI.contains.true.slope)
#--------- modify the above code a little bit to determine statistical power ------
rm(list = ls())
rm(list = ls())
rm(list = ls())
rm(list = ls())
#Let's start with our basic data setup. I will actually be using a mostly-clean SPSS file this time since this is likely the form that your data files will usually take.
rm(list = ls())
options(scipen=20)
options(digits=4) #show 4 digits when displaying results (e.g., 0.000 or 00.00)
# setting up a population in which gre.q is positively related to gpa
population.N <- 10000
gpa <- rnorm(n=population.N,mean=3,sd=0.25)
hist(gpa, breaks=20)
gre.q <- 150 + 10*scale(gpa) + rnorm(n=population.N,mean=0,sd=10)
hist(gre.q, breaks=20)
plot(x=gpa, y=gre.q)
# confirming that gre.q is indeed positively related to gpa using lm()
lm.gre.gpa <- lm(gre.q ~ gpa)
intercept  <- lm.gre.gpa$coef[1]
slope      <- lm.gre.gpa$coef[2]
cat("gre.q =",round(intercept,2), "+", round(slope,2),"* gpa\n")
# plotting the regression line using the intercept and slope from the above
lines(x=c(min(gpa),max(gpa)),
y=c(intercept+slope*min(gpa), intercept+slope*max(gpa)),
col=2,lw=3)
# defining a new function called onestudy
onestudy <- function(x, y, sample.size, color, show.lines=F, show.points=F) {
participants <- sample(length(x),size=sample.size)
x <- x[participants]
y <- y[participants]
if (show.points) points(x,y, col=color)
lm.result   <- lm(y ~ x)
intercept   <- lm.result$coef[1]
slope       <- lm.result$coef[2]
if (show.lines) {
lines(x=c(min(x),max(x)),
y=c(intercept+slope*min(x), intercept+slope*max(x)),
col=color)
}
return(lm.result)
}
# let's run onestudy() and see the result
onestudy.result <- onestudy(x=gpa, y=gre.q, sample.size=10, color=3, show.lines=T, show.points=T)
cat("gre.q =",round(onestudy.result$coef[1],2),
"+", round(onestudy.result$coef[2],2),"* gpa\n")
# let's do that again
onestudy.result <- onestudy(x=gpa, y=gre.q, sample.size=10, color=5, show.lines=T, show.points=T)
cat("gre.q =",round(onestudy.result$coef[1],2),
"+", round(onestudy.result$coef[2],2),"* gpa\n")
# let's do that 10 times
# move cursor to the console window and press return
plot(x=gpa, y=gre.q, type='n')
for (i in 1:10) {
readline(prompt=paste("Round",i,"of 10: Press return when ready:"))
onestudy(x=gpa, y=gre.q, sample.size=10,color=i,show.lines=T, show.points=T)
}
# let's do that 100 times
plot(x=gpa, y=gre.q, type='n')
for (i in 1:100) {
cat("Study",i,"\n")
onestudy(x=gpa, y=gre.q, sample.size=10,color=i,show.lines=T)
}
# let's do that 5000 times, and let's keep track of the intercept and slope from each study
sample.intercepts <- NULL
sample.slopes     <- NULL
plot(x=gpa, y=gre.q, type='n')
for (i in 1:5000) {
cat("Study",i,"\n")
onestudy.result <- onestudy(x=gpa, y=gre.q, sample.size=10, color=i, show.lines=T, show.points=F)
sample.intercepts <- append(sample.intercepts, onestudy.result$coef[1])
sample.slopes     <- append(sample.slopes, onestudy.result$coef[2])
}
# First, let's remind us of the population intercept and slope
lm.gre.gpa <- lm(gre.q ~ gpa)
intercept  <- lm.gre.gpa$coef[1]
slope      <- lm.gre.gpa$coef[2]
cat("gre.q =",round(intercept,2), "+", round(slope,2),"* gpa\n")
# Now, let's see the sampling distribution of intercepts across the 5000 studies
hist(sample.intercepts, breaks=20)
length(sample.slopes[sample.slopes > 160])
length(sample.slopes[sample.slopes > 150])
length(sample.slopes[sample.slopes > 100])
length(sample.slopes[sample.slopes > 30])
length(sample.slopes[sample.slopes > 80])
length(sample.slopes[sample.slopes > 80])/5000
length(sample.slopes[sample.slopes < - 80])
length(sample.slopes[sample.slopes < -80])
length(sample.slopes[sample.slopes > 60])/5000
length(sample.slopes[sample.slopes < -60])
length(sample.slopes[sample.slopes < - 60])
length(sample.slopes[sample.slopes < - 20])
length(sample.slopes[sample.slopes < - 5])
length(sample.slopes[sample.slopes > 5]) + length(sample.slopes[sample.slopes < - 5])
length(sample.slopes[sample.slopes > 5])/5000 #one tailed
length(sample.slopes[sample.slopes > 60])/5000 #one tailed
length(sample.slopes[sample.slopes > 5]) + length(sample.slopes[sample.slopes < - 5])
length(sample.slopes[sample.slopes > 60]) + length(sample.slopes[sample.slopes < - 5])
(length(sample.slopes[sample.slopes > 60]) + length(sample.slopes[sample.slopes < - 5]))/5000
length(sample.slopes[sample.slopes > 60])/5000 #one tailed
rm(list = ls())
# setting up a population in which gre.q is positively related to gpa
population.N <- 100000 # note I increased this to 100,000 so the population
# more closely approximates the true 'null' population
gpa <- rnorm(n=population.N,mean=3,sd=0.25)
# below creates gre.q such that it is strongly and positively related to gpa
gre.q <- 150 + 10*scale(gpa) + rnorm(n=population.N,mean=0,sd=10)
# below creates gre.q such that it is is unrelated to gpa
gre.q <- 150  + rnorm(n=population.N,mean=0,sd=10)
zgpa <- scale(gpa)
zgre.q <- scale(gre.q)
plot(x=zgpa, y=zgre.q, main=paste("The population. r =",round(cor(zgpa,zgre.q),2)))
# defining a new function called onestudy
onestudy <- function(x, y, sampling.distribution.of.size, color, show.lines=F, show.points=F) {
participants <- sample(length(x),size=sampling.distribution.of.size)
x <- x[participants]
y <- y[participants]
if (show.points) points(x,y, col=color)
lm.result   <- lm(y ~ x)
intercept   <- lm.result$coef[1]
slope       <- lm.result$coef[2]
if (show.lines) {
lines(x=c(min(x),max(x)),
y=c(intercept+slope*min(x), intercept+slope*max(x)),
col=color)
}
return(lm.result)
}
# let's do that 5000 times, and let's keep track of the intercept and slope from each study
sampling.distribution.of.slope     <- NULL
plot(x=zgpa, y=zgre.q, type='n', main=("Sampling distribution of slope"), xlim=c(-4,4),ylim=c(-4,4))
for (i in 1:5000) {
cat("Study",i,"\n")
onestudy.result <- onestudy(x=zgpa, y=zgre.q, sampling.distribution.of.size=10, color=i, show.lines=T, show.points=F)
slope <- summary(onestudy.result)$coef[2,1]
sampling.distribution.of.slope    <- append(sampling.distribution.of.slope, slope)
}
setwd("c:\\temp")
# pdf("sampling.distribution.of.slope.pdf")
hist(sampling.distribution.of.slope, breaks=20)
# dev.off()
cat("mean(sampling.distribution.of.slope) =",mean(sampling.distribution.of.slope),"\n")
# let's see the sampling distribution of p across the 5000 studies
# let's see the sampling distribution of p across the 5000 studies
# pdf("sampling.distribution.of.p.pdf")
# let's see the sampling distribution of p across the 5000 studies
# pdf("sampling.distribution.of.p.pdf")
# let's see the sampling distribution of p across the 5000 studies
# pdf("sampling.distribution.of.p.pdf")
rm(list = ls())
population.N <- 100000
gpa <- rnorm(n=population.N,mean=3,sd=0.25)
gre.q <- 150 + 10*scale(gpa) + rnorm(n=population.N,mean=0,sd=10)
zgpa <- scale(gpa)
zgre.q <- scale(gre.q)
plot(x=zgpa, y=zgre.q, main=paste("The population. r =",round(cor(zgpa,zgre.q),2)))
onestudy <- function(x, y, sampling.distribution.of.size, color, show.lines=F, show.points=F) {
participants <- sample(length(x),size=sampling.distribution.of.size)
x <- x[participants]
y <- y[participants]
if (show.points) points(x,y, col=color)
lm.result   <- lm(y ~ x)
intercept   <- lm.result$coef[1]
slope       <- lm.result$coef[2]
if (show.lines) {
lines(x=c(min(x),max(x)),
y=c(intercept+slope*min(x), intercept+slope*max(x)),
col=color)
}
return(lm.result)
}
sampling.distribution.of.slope     <- NULL
plot(x=zgpa, y=zgre.q, type='n', main=("Sampling distribution of slope"), xlim=c(-4,4),ylim=c(-4,4))
for (i in 1:5000) {
cat("Study",i,"\n")
onestudy.result <- onestudy(x=zgpa, y=zgre.q, sampling.distribution.of.size=10, color=i, show.lines=T, show.points=F)
slope <- summary(onestudy.result)$coef[2,1]
sampling.distribution.of.slope    <- append(sampling.distribution.of.slope, slope)
}
hist(sampling.distribution.of.slope, breaks=20)
length(sampling.distribution.of.slope[sampling.distribution.of.slope > .3])
length(sampling.distribution.of.slope[sampling.distribution.of.slope > .3])/5000 #one tailed
(length(sampling.distribution.of.slope[sampling.distribution.of.slope > .3]) + length(sampling.distribution.of.slope[sampling.distribution.of.slope < - .3]))/5000 #two tailed
rm(list = ls())
setwd("~/Desktop/UW/Winter '18/Linear Models & Data Analysis/525")
milestone <- load(file="milestone1_data.csv")
milestone <- load(file=milestone1_data.csv)
milestone <- read.csv("milestone1_data.csv")
View(milestone)
m1<- exam_score ~ studytime
lm.milestone<- lm(m1, data = milesone)
lm.milestone<- lm(m1, data = milestone)
m1<- exam_score ~ study_time
lm.milestone<- lm(m1, data = milestone)
lm.milestone
summary(lm.milestone)
plot(x=study_time, y=exam_score, main=paste("The population. r =",round(cor(study_time,exam_score.q),2)))
names(lm.milestone)
names(m1)
names(milestone)
?plot
milestone
plot(x=study_time, y=exam_score, main=paste("The population. r =",round(cor(study_time,exam_score.q),2)))
plot(milestone, x=study_time, y=exam_score, main=paste("The population. r =",round(cor(study_time,exam_score.q),2)))
plot(x=study_time, y=exam_score, main=paste("The population. r =",round(cor(study_time,exam_score.q),2)) data=milestone)
milestone
plot(milestone, main=paste("The population. r =",round(cor(study_time,exam_score.q),2)))
plot(milestone, main=paste("The population. r =",round(cor(study_time,exam_score),2)))
cor(study_time,exam_score)
cor(study_time,exam_score)
cor(x=study_time,y=exam_score)
cor(x=study_time,y=exam_score, data=milestone)
?cor
plot(milestone, main=paste("The population. r =",round(cor(study_time),2)))
cor(milestone, method="pearson")
plot(milestone, main=paste("The population. r =",round(cor(milestone, method="pearson"),2)))
require(psych)
psych::describe(milestone)
psych::describe(lm.milestone)
psych::describe(m1)
require(psych)
require(QuantPsyc)
require(foreign)
gre.gpa<-read.csv("https://raw.githubusercontent.com/connorjmccabe/Regression_523.525_2018/master/GPA_GRE_Q.csv") #You can read in csv files directly from github
View(gre.gpa) #the capitol in V is important
#Create summary tables
desc<-psych::describe(gre.gpa) #looking for the describe function from within the psych package. In this case it's because there are multiple programs that have the describe function. This may make it possible to circumvent loading the package itself.
#examine specific variables
desc[1,3]
#a dataframe is a specific type of list. typeof(desc) will show list as the type.
desc
#examine specific variables
desc[1,3]
desc["GRE.Q","mean"] #mean here is just referencing
desc[2,] #return row 2 of desc data.
#examine variable names
names(gre.gpa)
#working with individual variables
#OK:
gre.gpa[,2]
#Better:
gre.gpa$GRE.Q
gre.gpa[gre.gpa==9999]<-NA #For all values in this data.frame that equal 9999 assign them to NA
#computing means, SDs
mean(gre.gpa$GRE.Q) #if you have even one NA these kinds of functions wont
mean(gre.gpa$GRE.Q, na.rm = TRUE)#Removes NAs from variable
sd(gre.gpa$GRE.Q, na.rm = TRUE)
#Standardizing variables
scale(gre.gpa$GRE.Q)
scale(gre.gpa$GRE.Q, scale = FALSE)
#Can we check if scale() is working?
mean(scale(gre.gpa$GRE.Q)) #this shows part of the central limit theorem. Adding all of these values should result in zero
sd(scale(gre.gpa$GRE.Q)) # this should be 1
mean(scale(gre.gpa$GRE.Q, scale = FALSE)) #this centers your data at zero without standardizing it
sd(scale(gre.gpa$GRE.Q, scale = FALSE)) #as a result the standard deviation here will not change
m1<- GRE.Q ~ College.GPA # ~ this means "regressed onto". At this stage the things packed into m1 could be referrnig to anything in any data set you have loaded.
lm.gre.gpa<-lm(m1,data = gre.gpa)
#3. Examine results
lm.gre.gpa
summary(lm.gre.gpa)
names(lm.gre.gpa) #Really handy way to get a sense of an object and what objects are in the list
psych::describe(milestone)
lm.milestone["fitted.values"]
mean(lm.milestone["fitted.values"])
mean(lm.milestone$fitted.values)
summary(lm.milestone)
psych::describe(milestone)
mean(milestone$study_time)
mean(milestone$exam_score)
sd(lm.milestone$fitted.values)
names(lm.gre.gpa) #Really handy way to get a sense of an object and what objects are in the list
mean(lm.milestone$residuals)
sd(lm.milestone$residuals)
res2<-lm.milestone$residuals^2
mean(res2)
res2
lm.milestone$residuals
?var
?var
var(lm.milestone$coefficients)
lm.milestone$coefficients
var(milestone$study_time)
var(milestone$exam_score)
var(lm.milestone$fitted.values)
var(lm.milestone$residuals)
var(lm.milestone$fitted.values)/var(milestone$exam_score)
1-(var(lm.milestone$fitted.values)/var(milestone$exam_score))
.88*(sd(milestone$study_time)/sd(milestone$exam_score))
r<-.88*(sd(milestone$study_time)/sd(milestone$exam_score))
r
#2i creating the plot with the requested parameters
apatheme<-theme_bw()+
theme(
panel.grid.major=element_blank(),
panel.grid.minor=element_blank(),
panel.border=element_blank(),
axis.line=element_line(),
legend.title=element_blank()
)
nicescatter<-cmplot(df=gre.gpa,xvar=gre.gpa$College.GPA,yvar=gre.gpa$GRE.Q) +
stat_smooth(method = "lm", formula = y ~ x, color = "black", se=T) #smoothing function based on a linear model ("lm"). Here, ggplot is basically doing bivariate regression on the back end. the formula argument here shows the default.
options(scipen=20)
options(digits=4) #show 4 digits when displaying results (e.g., 0.000 or 00.00)
gre.gpa<-read.csv("https://raw.githubusercontent.com/connorjmccabe/Regression_523.525_2018/master/GPA_GRE_Q.csv")
#Reading in a file from my local computer:
setwd("~/Dropbox/UW Stats WD")
setwd("~/Desktop/UW/Winter '18/Linear Models & Data Analysis/523/WD")
gre.gpa<-read.csv("GPA_GRE_Q.csv")
gre.gpa<-read.csv("https://raw.githubusercontent.com/connorjmccabe/Regression_523.525_2018/master/GPA_GRE_Q.csv")
require(dplyr)
gre.gpa<- gre.gpa %>% #re-define my data as itself, and then...
mutate_all(funs(as.numeric), c("College.GPA","GRE.Q"))
#Below,
gre.gpa.scaled<- gre.gpa %>% #define object gre.gpa.scaled, and then...
transmute_all(funs(scale)) #standardize (get z score) by centering at zero and diving by the standard deviation
#First, let's get oriented to how ggplot2 works, without using data just yet.
#ggplot2 uses "layers" to build a plot to one's liking. Think of it like a canvas with layers of paint on top.
#Here is the most basic plot you can make - a blank canvas.
require(ggplot2)
ggplot()
ggplot() +
theme_bw()
qplot(College.GPA, data = gre.gpa) + theme_bw()  #qplot stands for quick plot, it's useful for getting quick and dirty histograms for you data
ggplot() +
geom_histogram(data=gre.gpa, aes(x=College.GPA)) +
theme_bw()
ggplot() +
xlim(-3,3) + #set the limits of the x-axis to -3 and 3
ylim(-3,3) + #set the limits of the y-axis to -3 and 3 as well
geom_hline(yintercept = 0) + #put a horizontal line at y=0
geom_vline(xintercept = 0, linetype = "dashed") + #put a vertical dashed line at x=0
# geom_vline(xintercept = 0, linetype = "solid") +
theme_bw()
?linetype
apatheme<-theme_bw()+
theme(
panel.grid.major=element_blank(), #No major gridlines
panel.grid.minor=element_blank(), #No minor gridlines
panel.border=element_blank(), #No panel border
axis.line=element_line(), #No axis lines
legend.title=element_blank() #No legend
)
ggplot() +
xlim(-3,3) +
ylim(-3,3) +
geom_hline(yintercept = 0) +
geom_vline(xintercept = 0, linetype = "dotdash") +
# geom_vline(xintercept = 0, linetype = "solid") +
apatheme
baseplot <- ggplot()
baseplot #blank canvas.
baseplot1 <- baseplot + xlim(-3,3) + ylim(-3,3)
baseplot1 #blank canvas with x and y limits.
baseplot2 <- baseplot1 + geom_hline(yintercept = 0)
baseplot2 #blank canvas with x and y limits and a horizonal line at 0 for some reason.
#etc.
baseplot3<-baseplot2 + apatheme
baseplot3
ggplot(data=gre.gpa, aes(x=College.GPA, y=GRE.Q))
ggplot() +
geom_point(data=gre.gpa, aes(x=College.GPA, y=GRE.Q)) +
theme_classic()
ggplot(data=gre.gpa, aes(x=College.GPA, y=GRE.Q)) +
geom_point() +
theme_bw()
#Here are other critical aesthetics:
?color
?fill
?group
gre.gpa$female<-rbinom(n=nrow(gre.gpa),size = 1,prob = .4)
gre.gpa$female<-as.factor(gre.gpa$female)
#Color donotes what aesthetic will be described based on differences in color, e.g.:
ggplot(gre.gpa, aes(x=College.GPA, y=GRE.Q, color = female)) +
geom_point() +
scale_color_manual(values=c("green", "blue")) + #useful for assigning color
#geom_point(colour = 'green')  #is an alternative to the above if you need just one color assigned
theme_bw()
#If you wanted to do it in a more comprehensive way you could define the variables like before
gre.gpa$female<-rbinom(n=nrow(gre.gpa),size = 1,prob = .4)
#then specify labels for your categories
gre.gpa$female[gre.gpa$female=="0"]<-"male"
gre.gpa$female[gre.gpa$female=="1"]<-"female"
#then rename the variable
gre.gpa$Gender<-gre.gpa$female
gre.gpa$female<-NULL
View(gre.gpa)
#then finally run the plot as before
ggplot(gre.gpa, aes(x=College.GPA, y=GRE.Q, color = Gender)) +
geom_point() +
scale_color_manual(values=c("green", "blue")) + #useful for assigning color
#geom_point(colour = 'green')  #is an alternative to the above if you need just one color assigned
theme_bw()
#Fill is another color aesthetic, but refers specifically to what the inside of a figure's color will be.
ggplot(gre.gpa, aes(x=College.GPA, y=GRE.Q, shape = female)) +
geom_point() +
theme_bw()
#Here are some ways I can doll it up a bit more to my liking:
ggplot(gre.gpa, aes(x=College.GPA, y=GRE.Q)) +
geom_point(size = .5, color = "blue", shape = 16, alpha = .5) + #size, color, and shape refer to the size, color, and shape of the points (no way!), and alpha refers to how transparent your points are. I use this to help audiences quickly identify where the data are clustered (overlapping points make areas that are darker).
theme_bw()
gre.gpa.scatter<-ggplot(gre.gpa, aes(x=College.GPA, y=GRE.Q)) +
geom_point(shape=16, size = 1) +
ylim(min(gre.gpa$GRE.Q,na.rm=T) - sd(gre.gpa$GRE.Q,na.rm=T),max(gre.gpa$GRE.Q,na.rm=T) + sd(gre.gpa$GRE.Q,na.rm=T)) + #this gives y axis limits. What's a savvier way of doing this?
#Here, I specify all my nitty-gritty details to pretty it up.
theme(text=element_text(size=16, color="black"), #Use size 30 black text
# axis.text.x=element_text(colour="black"), #dont need because of element_text
# axis.text.y=element_text(colour="black"), #dont need because of element_text
axis.title.y=element_text(size=20), #change y axis title size to be a bit bigger than everything else
panel.background = element_rect(fill = 'white'), #make plot background white
panel.grid.major = element_line(colour="#C0C0C0"), #make major grid panel a specific shade of grey (of of fifty).
# panel.grid.minor = element_line(colour="#C0C0C0"), #set minor grid panels to that color too
# lefemaled.background= element_rect(fill="white", colour=NA), #Don't need
plot.background=element_rect(fill='white')) + #make plot background white
labs(x = "GPA", y= "GRE \n Quantitiative") #\n tells the code to place the next component on the new line thing on a new line
gre.gpa.scatter
cmplot<-function(df, xvar, yvar){
ggplot(data=df, aes(x=xvar,y=yvar)) +
geom_point(shape=16, size = 1) +
ylim(min(yvar,na.rm=T) - sd(yvar,na.rm=T),max(yvar,na.rm=T) + sd(yvar,na.rm=T)) + #this gives y axis limits. What's a savvier way of doing this?
xlim(min(xvar,na.rm=T) - sd(xvar,na.rm=T),max(xvar,na.rm=T) + sd(xvar,na.rm=T)) + #this gives y axis limits. What's a savvier way of doing this?
#Here, I specify all my nitty-gritty details to pretty it up.
theme(text=element_text(size=16, color="black"), #Use size 30 black text
# axis.text.x=element_text(colour="black"), #dont need because of element_text
# axis.text.y=element_text(colour="black"), #dont need because of element_text
axis.title.y=element_text(size=20), #change y axis title size to be a bit bigger than everything else
panel.background = element_rect(fill = 'white'), #make plot background white
panel.grid.major = element_line(colour="#C0C0C0"), #make major grid panel a specific shade of grey (of of fifty).
# panel.grid.minor = element_line(colour="#C0C0C0"), #set minor grid panels to that color too
# lefemaled.background= element_rect(fill="white", colour=NA), #Don't need
plot.background=element_rect(fill='white')) + #make plot background white
labs(x = "GPA", y= "GRE \n Quantitiative")
}
plot.unstd<-cmplot(df=gre.gpa,xvar=gre.gpa$College.GPA,yvar=gre.gpa$GRE.Q) #Somewhat annoying: this function can only take vector objects for xvar and yvar since it's not operating directly within ggplot
plot.unstd
#We can also customize our plots after-the-fact by calling our ggplot object and adding elements to it. e.g.:
plot.unstd + geom_point(color="blue")
#Remember the scaled variable dataset we created? Let's make a plot of that and compare.
plot.std<-cmplot(df=gre.gpa.scaled,xvar=gre.gpa.scaled$College.GPA,yvar=gre.gpa.scaled$GRE.Q)
plot.std + geom_point(color="red")
# we can make side-by-side plots using grid.arrange from the gridExtra package
require(gridExtra)
grid.arrange(plot.unstd + geom_point(color="blue") + ggtitle("UNSTANDARDIZED"),
plot.std + geom_point(color="red") + ggtitle("STANDARDIZED"))
nicescatter<-cmplot(df=gre.gpa,xvar=gre.gpa$College.GPA,yvar=gre.gpa$GRE.Q) +
stat_smooth(method = "lm", formula = y ~ x, color = "black", se=T) #smoothing function based on a linear model ("lm"). Here, ggplot is basically doing bivariate regression on the back end. the formula argument here shows the default.
nicescatter
#2i creating the plot with the requested parameters
apatheme<-theme_bw()+
theme(
panel.grid.major=element_blank(),
panel.grid.minor=element_blank(),
panel.border=element_blank(),
axis.line=element_line(),
legend.title=element_blank()
)
milestoneplot<-function(df, xvar, yvar){
ggplot(data=df, aes(x=xvar,y=yvar)) +
geom_point(shape=16, size = 1) +
ylim(min(yvar,na.rm=T) - sd(yvar,na.rm=T),max(yvar,na.rm=T) + sd(yvar,na.rm=T)) +
xlim(min(xvar,na.rm=T) - sd(xvar,na.rm=T),max(xvar,na.rm=T) + sd(xvar,na.rm=T)) +
apatheme +
labs(x = "Hours of Study", y= "Exam \n Scores")
}
plot.unstd<-milestoneplot(df=milestone,xvar=milestone$study_time,yvar=milestone$exam_score)
plot.unstd
View(milestone)
View(milestone)
#We can also customize our plots after-the-fact by calling our ggplot object and adding elements to it. e.g.:
plot.unstd + geom_point(color="blue")
nicescatter<-milestoneplot(df=milestone,xvar=milestone$study_time,yvar=milestone$exam_score) +
stat_smooth(method = "lm", formula = y ~ x, color = "black", se=T) #smoothing function based on a linear model ("lm"). Here, ggplot is basically doing bivariate regression on the back end. the formula argument here shows the default.
nicescatter
milestoneplot<-function(df, xvar, yvar){
ggplot(data=df, aes(x=xvar,y=yvar)) +
geom_point(shape=16, size = 1) +
ylim(min(yvar,na.rm=T) - sd(yvar,na.rm=T),max(yvar,na.rm=T) + sd(yvar,na.rm=T)) +
xlim(min(xvar,na.rm=T) - sd(xvar,na.rm=T),max(xvar,na.rm=T) + sd(xvar,na.rm=T)) +
apatheme +
labs(x = "Hours of Study", y= "Exam \n Scores")
ggtitle("Milestone Question 2i", subtitle = "Regression of Exam Score on Study Time")
}
nicescatter<-milestoneplot(df=milestone,xvar=milestone$study_time,yvar=milestone$exam_score) +
stat_smooth(method = "lm", formula = y ~ x, color = "black", se=T)
nicescatter
milestoneplot<-function(df, xvar, yvar){
ggplot(data=df, aes(x=xvar,y=yvar)) +
geom_point(shape=16, size = 1) +
ylim(min(yvar,na.rm=T) - sd(yvar,na.rm=T),max(yvar,na.rm=T) + sd(yvar,na.rm=T)) +
xlim(min(xvar,na.rm=T) - sd(xvar,na.rm=T),max(xvar,na.rm=T) + sd(xvar,na.rm=T)) +
apatheme +
labs(x = "Hours of Study", y= "Exam \n Scores") +
ggtitle("Milestone Question 2i", subtitle = "Regression of Exam Score on Study Time")
}
nicescatter<-milestoneplot(df=milestone,xvar=milestone$study_time,yvar=milestone$exam_score) +
stat_smooth(method = "lm", formula = y ~ x, color = "black", se=T)
nicescatter
